{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimum learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, InputLayer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.python.keras import utils\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import imageio \n",
    "from PIL import Image \n",
    "import keras_lr_finder as lr_find # For finding optimum learning rate [pip install keras_lr_finder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anaswara\\AppData\\Local\\Temp\\ipykernel_6892\\3381015795.py:8: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img = imageio.imread(img_path)\n"
     ]
    }
   ],
   "source": [
    "# Reading the data\n",
    "train = pd.read_csv('agedetectiontrain/train.csv')\n",
    "\n",
    "# Image resizing of test data into single numpy array\n",
    "temp = []\n",
    "for img_name in train.ID:\n",
    "    img_path = os.path.join('agedetectiontrain/Train', img_name)\n",
    "    img = imageio.imread(img_path)\n",
    "    img = np.array(Image.fromarray(img).resize((32, 32))).astype('float32')    \n",
    "    temp.append(img)\n",
    "\n",
    "train_x = np.stack(temp)\n",
    "\n",
    "# Normalizing the images\n",
    "train_x = train_x / 255.\n",
    "\n",
    "# Encoding the categorical variable to numeric\n",
    "lb = LabelEncoder()\n",
    "train_y = lb.fit_transform(train.Class)\n",
    "train_y = keras.utils.to_categorical(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specifying all the parameters we will be using in our network\n",
    "input_num_units = (32, 32, 3)\n",
    "hidden_num_units = 500\n",
    "output_num_units = 3\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anaswara\\anaconda3\\envs\\deepl-env\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=input_num_units), # Perform conversion of higher dimensional data (here, 2-D) to 1-D data.\n",
    "    keras.layers.Dense(hidden_num_units, activation=tf.nn.relu), # Hidden layer with 500 neurons and ReLU activation function\n",
    "    keras.layers.Dense(output_num_units, activation=tf.nn.softmax) # Output layer with softmax activation function \n",
    "])                                                   # which gives final output in terms of probability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining parameters like optmizer, loss function and evaluating metric\n",
    "model.compile(loss='categorical_crossentropy', # \n",
    "              optimizer=keras.optimizers.Adam(), # Learning rate and momentum can be passed inside optimizer\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The filename must end in `.weights.h5`. Received: filepath=tmp.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m lr_finder = lr_find.LRFinder(model)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Training can stop abruptly if rate is set too high. In such cases, reduce the value of end_lr. \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mlr_finder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_lr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_lr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.09\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anaswara\\anaconda3\\envs\\deepl-env\\Lib\\site-packages\\keras_lr_finder\\lr_finder.py:45\u001b[39m, in \u001b[36mLRFinder.find\u001b[39m\u001b[34m(self, x_train, y_train, start_lr, end_lr, batch_size, epochs)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28mself\u001b[39m.lr_mult = (end_lr / start_lr) ** (\u001b[32m1\u001b[39m / num_batches)\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Save weights into a file\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtmp.h5\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# Remember the original learning rate\u001b[39;00m\n\u001b[32m     48\u001b[39m original_lr = K.get_value(\u001b[38;5;28mself\u001b[39m.model.optimizer.lr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anaswara\\anaconda3\\envs\\deepl-env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anaswara\\anaconda3\\envs\\deepl-env\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:227\u001b[39m, in \u001b[36msave_weights\u001b[39m\u001b[34m(model, filepath, overwrite, max_shard_size, **kwargs)\u001b[39m\n\u001b[32m    225\u001b[39m filepath_str = \u001b[38;5;28mstr\u001b[39m(filepath)\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m max_shard_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filepath_str.endswith(\u001b[33m\"\u001b[39m\u001b[33m.weights.h5\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    228\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe filename must end in `.weights.h5`. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    229\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReceived: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    230\u001b[39m     )\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m max_shard_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filepath_str.endswith(\n\u001b[32m    232\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mweights.h5\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mweights.json\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    233\u001b[39m ):\n\u001b[32m    234\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    235\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe filename must end in `.weights.json` when `max_shard_size` is \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    236\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mspecified. Received: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    237\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: The filename must end in `.weights.h5`. Received: filepath=tmp.h5"
     ]
    }
   ],
   "source": [
    "lr_finder = lr_find.LRFinder(model)\n",
    "\n",
    "# Training can stop abruptly if rate is set too high. In such cases, reduce the value of end_lr. \n",
    "lr_finder.find(train_x, train_y, start_lr=0.0001, end_lr=0.09, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lr_finder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Plot the loss, ignore 20 batches in the beginning and 5 in the end\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mlr_finder\u001b[49m.plot_loss(n_skip_beginning=\u001b[32m20\u001b[39m, n_skip_end=\u001b[32m5\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'lr_finder' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot the loss, ignore 20 batches in the beginning and 5 in the end\n",
    "lr_finder.plot_loss(n_skip_beginning=20, n_skip_end=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the above figure following learning rate can be choosen due to fast decrease in loss -\n",
    "* base_lr = $10^{-4}$\n",
    "* max_lr = $10^{-3}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting cyclic learning rate for model training\n",
    "Ensure you have `clr_callback.py` file in the same directory of current module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from clr_callback import * # Importing cyclic learning rate module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pass the values of base_lr with the value of \n",
    "cb_triangular = CyclicLR(base_lr=0.0001, max_lr=0.001, step_size=2000., mode='triangular2') # Setting callback for model\n",
    "\n",
    "# Writing graph will take time. Hence, keeping it False.\n",
    "cb_save = keras.callbacks.TensorBoard(log_dir='learning_rate', write_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15924 samples, validate on 3982 samples\n",
      "Epoch 1/100\n",
      "15924/15924 [==============================] - 10s 640us/step - loss: 0.6899 - acc: 0.7000 - val_loss: 0.6773 - val_acc: 0.7082\n",
      "Epoch 2/100\n",
      "15924/15924 [==============================] - 9s 593us/step - loss: 0.6884 - acc: 0.7008 - val_loss: 0.6762 - val_acc: 0.7094\n",
      "Epoch 3/100\n",
      "15924/15924 [==============================] - 12s 747us/step - loss: 0.6882 - acc: 0.7021 - val_loss: 0.6766 - val_acc: 0.7104\n",
      "Epoch 4/100\n",
      "15924/15924 [==============================] - 11s 669us/step - loss: 0.6847 - acc: 0.7038 - val_loss: 0.6761 - val_acc: 0.7077\n",
      "Epoch 5/100\n",
      "15924/15924 [==============================] - 8s 498us/step - loss: 0.6841 - acc: 0.7051 - val_loss: 0.6740 - val_acc: 0.7074\n",
      "Epoch 6/100\n",
      "15924/15924 [==============================] - 8s 503us/step - loss: 0.6830 - acc: 0.7058 - val_loss: 0.6759 - val_acc: 0.7140\n",
      "Epoch 7/100\n",
      "15924/15924 [==============================] - 9s 541us/step - loss: 0.6825 - acc: 0.7081 - val_loss: 0.6749 - val_acc: 0.7165\n",
      "Epoch 8/100\n",
      "15924/15924 [==============================] - 13s 828us/step - loss: 0.6809 - acc: 0.7050 - val_loss: 0.6721 - val_acc: 0.7112\n",
      "Epoch 9/100\n",
      "15924/15924 [==============================] - 12s 762us/step - loss: 0.6794 - acc: 0.7081 - val_loss: 0.6732 - val_acc: 0.7152\n",
      "Epoch 10/100\n",
      "15924/15924 [==============================] - 12s 745us/step - loss: 0.6751 - acc: 0.7087 - val_loss: 0.6755 - val_acc: 0.7135\n",
      "Epoch 11/100\n",
      "15924/15924 [==============================] - 10s 650us/step - loss: 0.6735 - acc: 0.7134 - val_loss: 0.6795 - val_acc: 0.7107\n",
      "Epoch 12/100\n",
      "15924/15924 [==============================] - 9s 574us/step - loss: 0.6752 - acc: 0.7077 - val_loss: 0.6725 - val_acc: 0.7059\n",
      "Epoch 13/100\n",
      "15924/15924 [==============================] - 8s 533us/step - loss: 0.6744 - acc: 0.7083 - val_loss: 0.6716 - val_acc: 0.7150\n",
      "Epoch 14/100\n",
      "15924/15924 [==============================] - 10s 620us/step - loss: 0.6687 - acc: 0.7113 - val_loss: 0.6695 - val_acc: 0.7185\n",
      "Epoch 15/100\n",
      "15924/15924 [==============================] - 10s 613us/step - loss: 0.6661 - acc: 0.7128 - val_loss: 0.6677 - val_acc: 0.7125\n",
      "Epoch 16/100\n",
      "15924/15924 [==============================] - 9s 577us/step - loss: 0.6634 - acc: 0.7161 - val_loss: 0.6788 - val_acc: 0.7044\n",
      "Epoch 17/100\n",
      "15924/15924 [==============================] - 9s 555us/step - loss: 0.6756 - acc: 0.7072 - val_loss: 0.6850 - val_acc: 0.7002\n",
      "Epoch 18/100\n",
      "15924/15924 [==============================] - 9s 580us/step - loss: 0.6654 - acc: 0.7140 - val_loss: 0.6726 - val_acc: 0.7067\n",
      "Epoch 19/100\n",
      "15924/15924 [==============================] - 12s 771us/step - loss: 0.6557 - acc: 0.7188 - val_loss: 0.6719 - val_acc: 0.7044\n",
      "Epoch 20/100\n",
      "15924/15924 [==============================] - 12s 743us/step - loss: 0.6621 - acc: 0.7108 - val_loss: 0.6635 - val_acc: 0.7147\n",
      "Epoch 21/100\n",
      "15924/15924 [==============================] - 11s 677us/step - loss: 0.6562 - acc: 0.7217 - val_loss: 0.6676 - val_acc: 0.7072\n",
      "Epoch 22/100\n",
      "15924/15924 [==============================] - 10s 640us/step - loss: 0.6533 - acc: 0.7175 - val_loss: 0.6635 - val_acc: 0.7157\n",
      "Epoch 23/100\n",
      "15924/15924 [==============================] - 8s 524us/step - loss: 0.6473 - acc: 0.7211 - val_loss: 0.6758 - val_acc: 0.7027\n",
      "Epoch 24/100\n",
      "15924/15924 [==============================] - 10s 616us/step - loss: 0.6576 - acc: 0.7165 - val_loss: 0.6692 - val_acc: 0.7140\n",
      "Epoch 25/100\n",
      "15924/15924 [==============================] - 9s 569us/step - loss: 0.6520 - acc: 0.7175 - val_loss: 0.6585 - val_acc: 0.7160\n",
      "Epoch 26/100\n",
      "15924/15924 [==============================] - 10s 626us/step - loss: 0.6401 - acc: 0.7263 - val_loss: 0.6659 - val_acc: 0.7165\n",
      "Epoch 27/100\n",
      "15924/15924 [==============================] - 10s 638us/step - loss: 0.6402 - acc: 0.7276 - val_loss: 0.6564 - val_acc: 0.7200\n",
      "Epoch 28/100\n",
      "15924/15924 [==============================] - 9s 551us/step - loss: 0.6310 - acc: 0.7352 - val_loss: 0.6592 - val_acc: 0.7162\n",
      "Epoch 29/100\n",
      "15924/15924 [==============================] - 9s 587us/step - loss: 0.6350 - acc: 0.7273 - val_loss: 0.6944 - val_acc: 0.6996\n",
      "Epoch 30/100\n",
      "15924/15924 [==============================] - 9s 577us/step - loss: 0.6457 - acc: 0.7214 - val_loss: 0.6691 - val_acc: 0.7147\n",
      "Epoch 31/100\n",
      "15924/15924 [==============================] - 11s 681us/step - loss: 0.6258 - acc: 0.7351 - val_loss: 0.6659 - val_acc: 0.7155\n",
      "Epoch 32/100\n",
      "15924/15924 [==============================] - 16s 1ms/step - loss: 0.6240 - acc: 0.7349 - val_loss: 0.6702 - val_acc: 0.7115\n",
      "Epoch 33/100\n",
      "15924/15924 [==============================] - 10s 629us/step - loss: 0.6219 - acc: 0.7347 - val_loss: 0.6619 - val_acc: 0.7145\n",
      "Epoch 34/100\n",
      "15924/15924 [==============================] - 9s 559us/step - loss: 0.6195 - acc: 0.7376 - val_loss: 0.6931 - val_acc: 0.6904\n",
      "Epoch 35/100\n",
      "15924/15924 [==============================] - 9s 576us/step - loss: 0.6314 - acc: 0.7271 - val_loss: 0.6732 - val_acc: 0.7150\n",
      "Epoch 36/100\n",
      "15924/15924 [==============================] - 9s 593us/step - loss: 0.6160 - acc: 0.7425 - val_loss: 0.6937 - val_acc: 0.6984\n",
      "Epoch 37/100\n",
      "15924/15924 [==============================] - 9s 547us/step - loss: 0.6262 - acc: 0.7335 - val_loss: 0.6603 - val_acc: 0.7175\n",
      "Epoch 38/100\n",
      "15924/15924 [==============================] - 10s 600us/step - loss: 0.6165 - acc: 0.7383 - val_loss: 0.6557 - val_acc: 0.7192\n",
      "Epoch 39/100\n",
      "15924/15924 [==============================] - 9s 571us/step - loss: 0.6041 - acc: 0.7484 - val_loss: 0.6639 - val_acc: 0.7135\n",
      "Epoch 40/100\n",
      "15924/15924 [==============================] - 9s 577us/step - loss: 0.6063 - acc: 0.7405 - val_loss: 0.6879 - val_acc: 0.7054\n",
      "Epoch 41/100\n",
      "15924/15924 [==============================] - 9s 549us/step - loss: 0.6059 - acc: 0.7442 - val_loss: 0.6542 - val_acc: 0.7192\n",
      "Epoch 42/100\n",
      "15924/15924 [==============================] - 9s 573us/step - loss: 0.6011 - acc: 0.7466 - val_loss: 0.6718 - val_acc: 0.7192\n",
      "Epoch 43/100\n",
      "15924/15924 [==============================] - 9s 548us/step - loss: 0.5977 - acc: 0.7487 - val_loss: 0.6872 - val_acc: 0.7064\n",
      "Epoch 44/100\n",
      "15924/15924 [==============================] - 9s 554us/step - loss: 0.5900 - acc: 0.7540 - val_loss: 0.6752 - val_acc: 0.7079\n",
      "Epoch 45/100\n",
      "15924/15924 [==============================] - 9s 591us/step - loss: 0.6040 - acc: 0.7439 - val_loss: 0.6519 - val_acc: 0.7210\n",
      "Epoch 46/100\n",
      "15924/15924 [==============================] - 9s 544us/step - loss: 0.5939 - acc: 0.7479 - val_loss: 0.6576 - val_acc: 0.7167\n",
      "Epoch 47/100\n",
      "15924/15924 [==============================] - 9s 562us/step - loss: 0.5803 - acc: 0.7581 - val_loss: 0.6754 - val_acc: 0.7014\n",
      "Epoch 48/100\n",
      "15924/15924 [==============================] - 9s 545us/step - loss: 0.5848 - acc: 0.7545 - val_loss: 0.6982 - val_acc: 0.7024\n",
      "Epoch 49/100\n",
      "15924/15924 [==============================] - 10s 648us/step - loss: 0.6076 - acc: 0.7392 - val_loss: 0.6870 - val_acc: 0.7022\n",
      "Epoch 50/100\n",
      "15924/15924 [==============================] - 7s 450us/step - loss: 0.5765 - acc: 0.7604 - val_loss: 0.7425 - val_acc: 0.6823\n",
      "Epoch 51/100\n",
      "15924/15924 [==============================] - 12s 727us/step - loss: 0.6058 - acc: 0.7398 - val_loss: 0.6595 - val_acc: 0.7202\n",
      "Epoch 52/100\n",
      "15924/15924 [==============================] - 8s 509us/step - loss: 0.5747 - acc: 0.7593 - val_loss: 0.6651 - val_acc: 0.7185\n",
      "Epoch 53/100\n",
      "15924/15924 [==============================] - 8s 519us/step - loss: 0.5623 - acc: 0.7673 - val_loss: 0.6703 - val_acc: 0.7102\n",
      "Epoch 54/100\n",
      "15924/15924 [==============================] - 12s 754us/step - loss: 0.5742 - acc: 0.7591 - val_loss: 0.6535 - val_acc: 0.7240\n",
      "Epoch 55/100\n",
      "15924/15924 [==============================] - 9s 551us/step - loss: 0.5607 - acc: 0.7666 - val_loss: 0.6819 - val_acc: 0.6981\n",
      "Epoch 56/100\n",
      "15924/15924 [==============================] - 10s 638us/step - loss: 0.5561 - acc: 0.7721 - val_loss: 0.6536 - val_acc: 0.7177\n",
      "Epoch 57/100\n",
      "15924/15924 [==============================] - 8s 510us/step - loss: 0.5491 - acc: 0.7710 - val_loss: 0.6934 - val_acc: 0.7047\n",
      "Epoch 58/100\n",
      "15924/15924 [==============================] - 8s 520us/step - loss: 0.5661 - acc: 0.7619 - val_loss: 0.6618 - val_acc: 0.7195\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15924/15924 [==============================] - 7s 449us/step - loss: 0.5527 - acc: 0.7702 - val_loss: 0.6672 - val_acc: 0.7175\n",
      "Epoch 60/100\n",
      "15924/15924 [==============================] - 10s 598us/step - loss: 0.5730 - acc: 0.7521 - val_loss: 0.6681 - val_acc: 0.7145\n",
      "Epoch 61/100\n",
      "15924/15924 [==============================] - 9s 572us/step - loss: 0.5470 - acc: 0.7757 - val_loss: 0.6966 - val_acc: 0.7057\n",
      "Epoch 62/100\n",
      "15924/15924 [==============================] - 9s 567us/step - loss: 0.5452 - acc: 0.7756 - val_loss: 0.7644 - val_acc: 0.6725\n",
      "Epoch 63/100\n",
      "15924/15924 [==============================] - 10s 631us/step - loss: 0.5626 - acc: 0.7644 - val_loss: 0.6760 - val_acc: 0.7125\n",
      "Epoch 64/100\n",
      "15924/15924 [==============================] - 10s 652us/step - loss: 0.5399 - acc: 0.7797 - val_loss: 0.6722 - val_acc: 0.7115\n",
      "Epoch 65/100\n",
      "15924/15924 [==============================] - 11s 713us/step - loss: 0.5358 - acc: 0.7776 - val_loss: 0.7047 - val_acc: 0.6989\n",
      "Epoch 66/100\n",
      "15924/15924 [==============================] - 9s 555us/step - loss: 0.5439 - acc: 0.7701 - val_loss: 0.6757 - val_acc: 0.7175\n",
      "Epoch 67/100\n",
      "15924/15924 [==============================] - 10s 598us/step - loss: 0.5215 - acc: 0.7867 - val_loss: 0.6966 - val_acc: 0.7074\n",
      "Epoch 68/100\n",
      "15924/15924 [==============================] - 9s 550us/step - loss: 0.5264 - acc: 0.7823 - val_loss: 0.6850 - val_acc: 0.7067\n",
      "Epoch 69/100\n",
      "15924/15924 [==============================] - 10s 615us/step - loss: 0.5218 - acc: 0.7845 - val_loss: 0.6742 - val_acc: 0.7182\n",
      "Epoch 70/100\n",
      "15924/15924 [==============================] - 10s 611us/step - loss: 0.5183 - acc: 0.7854 - val_loss: 0.6855 - val_acc: 0.7049\n",
      "Epoch 71/100\n",
      "15924/15924 [==============================] - 13s 806us/step - loss: 0.5177 - acc: 0.7881 - val_loss: 0.6742 - val_acc: 0.7142\n",
      "Epoch 72/100\n",
      "15924/15924 [==============================] - 9s 559us/step - loss: 0.5084 - acc: 0.7925 - val_loss: 0.6664 - val_acc: 0.7167\n",
      "Epoch 73/100\n",
      "15924/15924 [==============================] - 8s 494us/step - loss: 0.4924 - acc: 0.8034 - val_loss: 0.7105 - val_acc: 0.6966\n",
      "Epoch 74/100\n",
      "15924/15924 [==============================] - 8s 483us/step - loss: 0.5147 - acc: 0.7876 - val_loss: 0.7224 - val_acc: 0.6994\n",
      "Epoch 75/100\n",
      "15924/15924 [==============================] - 9s 587us/step - loss: 0.5047 - acc: 0.7935 - val_loss: 0.6859 - val_acc: 0.7037\n",
      "Epoch 76/100\n",
      "15924/15924 [==============================] - 9s 555us/step - loss: 0.5001 - acc: 0.7963 - val_loss: 0.6771 - val_acc: 0.7130\n",
      "Epoch 77/100\n",
      "15924/15924 [==============================] - 9s 535us/step - loss: 0.4901 - acc: 0.8009 - val_loss: 0.7406 - val_acc: 0.6894\n",
      "Epoch 78/100\n",
      "15924/15924 [==============================] - 9s 553us/step - loss: 0.4961 - acc: 0.7983 - val_loss: 0.6828 - val_acc: 0.7084\n",
      "Epoch 79/100\n",
      "15924/15924 [==============================] - 10s 636us/step - loss: 0.4798 - acc: 0.8073 - val_loss: 0.7151 - val_acc: 0.6936\n",
      "Epoch 80/100\n",
      "15924/15924 [==============================] - 10s 626us/step - loss: 0.4890 - acc: 0.8026 - val_loss: 0.6826 - val_acc: 0.7099\n",
      "Epoch 81/100\n",
      "15924/15924 [==============================] - 12s 770us/step - loss: 0.4776 - acc: 0.8097 - val_loss: 0.6754 - val_acc: 0.7120\n",
      "Epoch 82/100\n",
      "15924/15924 [==============================] - 12s 736us/step - loss: 0.4713 - acc: 0.8135 - val_loss: 0.7032 - val_acc: 0.7062\n",
      "Epoch 83/100\n",
      "15924/15924 [==============================] - 12s 753us/step - loss: 0.4863 - acc: 0.8019 - val_loss: 0.6803 - val_acc: 0.7137\n",
      "Epoch 84/100\n",
      "15924/15924 [==============================] - 13s 820us/step - loss: 0.4687 - acc: 0.8120 - val_loss: 0.7045 - val_acc: 0.7027\n",
      "Epoch 85/100\n",
      "15924/15924 [==============================] - 9s 575us/step - loss: 0.4839 - acc: 0.8012 - val_loss: 0.6922 - val_acc: 0.7107\n",
      "Epoch 86/100\n",
      "15924/15924 [==============================] - 10s 659us/step - loss: 0.4692 - acc: 0.8125 - val_loss: 0.6692 - val_acc: 0.7175\n",
      "Epoch 87/100\n",
      "15924/15924 [==============================] - 12s 772us/step - loss: 0.4733 - acc: 0.8079 - val_loss: 0.6842 - val_acc: 0.7185\n",
      "Epoch 88/100\n",
      "15924/15924 [==============================] - 11s 706us/step - loss: 0.4780 - acc: 0.8048 - val_loss: 0.7075 - val_acc: 0.7092\n",
      "Epoch 89/100\n",
      "15924/15924 [==============================] - 8s 512us/step - loss: 0.4674 - acc: 0.8106 - val_loss: 0.6689 - val_acc: 0.7223\n",
      "Epoch 90/100\n",
      "15924/15924 [==============================] - 8s 516us/step - loss: 0.4523 - acc: 0.8210 - val_loss: 0.6685 - val_acc: 0.7225\n",
      "Epoch 91/100\n",
      "15924/15924 [==============================] - 12s 746us/step - loss: 0.4491 - acc: 0.8232 - val_loss: 0.6898 - val_acc: 0.7132\n",
      "Epoch 92/100\n",
      "15924/15924 [==============================] - 13s 812us/step - loss: 0.4522 - acc: 0.8205 - val_loss: 0.6958 - val_acc: 0.7112\n",
      "Epoch 93/100\n",
      "15924/15924 [==============================] - 10s 645us/step - loss: 0.4615 - acc: 0.8141 - val_loss: 0.6799 - val_acc: 0.7202\n",
      "Epoch 94/100\n",
      "15924/15924 [==============================] - 12s 764us/step - loss: 0.4530 - acc: 0.8195 - val_loss: 0.6796 - val_acc: 0.7190\n",
      "Epoch 95/100\n",
      "15924/15924 [==============================] - 8s 494us/step - loss: 0.4456 - acc: 0.8229 - val_loss: 0.6740 - val_acc: 0.7243\n",
      "Epoch 96/100\n",
      "15924/15924 [==============================] - 7s 451us/step - loss: 0.4403 - acc: 0.8255 - val_loss: 0.6754 - val_acc: 0.7243\n",
      "Epoch 97/100\n",
      "15924/15924 [==============================] - 7s 467us/step - loss: 0.4435 - acc: 0.8259 - val_loss: 0.7068 - val_acc: 0.7062\n",
      "Epoch 98/100\n",
      "15924/15924 [==============================] - 10s 618us/step - loss: 0.4516 - acc: 0.8232 - val_loss: 0.6784 - val_acc: 0.7187\n",
      "Epoch 99/100\n",
      "15924/15924 [==============================] - 10s 627us/step - loss: 0.4355 - acc: 0.8279 - val_loss: 0.6763 - val_acc: 0.7243\n",
      "Epoch 100/100\n",
      "15924/15924 [==============================] - 10s 614us/step - loss: 0.4301 - acc: 0.8325 - val_loss: 0.6774 - val_acc: 0.7215\n",
      "Model built sucessfully.\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_y, batch_size=batch_size, epochs=epochs, \n",
    "          validation_split=0.2, callbacks=[cb_triangular, cb_save], verbose=1)\n",
    "print('Model built sucessfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b7c78760b8>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b7c78760f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('Training Iterations')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title(\"CLR - 'triangular2' Policy\")\n",
    "plt.plot(cb_triangular.history['iterations'], cb_triangular.history['lr'])\n",
    "\n",
    "# With more number of iterations the graph will correspond to that of a traingular wave"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
