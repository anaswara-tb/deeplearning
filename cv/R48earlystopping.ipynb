{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, InputLayer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.python.keras import utils\n",
    "import keras\n",
    "import imageio \n",
    "from PIL import Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anaswara\\AppData\\Local\\Temp\\ipykernel_1256\\2433241514.py:8: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img = imageio.imread(img_path)\n"
     ]
    }
   ],
   "source": [
    "# Reading the data\n",
    "train = pd.read_csv('agedetectiontrain/train.csv')\n",
    "\n",
    "# Image resizing of test data into single numpy array\n",
    "temp = []\n",
    "for img_name in train.ID:\n",
    "    img_path = os.path.join('agedetectiontrain/Train', img_name)\n",
    "    img = imageio.imread(img_path)\n",
    "    img = np.array(Image.fromarray(img).resize((32, 32))).astype('float32')    \n",
    "    temp.append(img)\n",
    "\n",
    "train_x = np.stack(temp)\n",
    "\n",
    "# Normalizing the images\n",
    "train_x = train_x / 255.\n",
    "\n",
    "# Encoding the categorical variable to numer\n",
    "lb = LabelEncoder()\n",
    "train_y = lb.fit_transform(train.Class)\n",
    "train_y = keras.utils.to_categorical(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specifying all the parameters we will be using in our network\n",
    "input_num_units = (32, 32, 3)\n",
    "hidden_num_units = 500\n",
    "output_num_units = 3\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 36ms/step - accuracy: 0.5605 - loss: 1.0705 - val_accuracy: 0.5899 - val_loss: 0.8662\n",
      "Epoch 2/100\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 32ms/step - accuracy: 0.6103 - loss: 0.8324 - val_accuracy: 0.6261 - val_loss: 0.8006\n",
      "Epoch 3/100\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 32ms/step - accuracy: 0.6192 - loss: 0.8141 - val_accuracy: 0.6336 - val_loss: 0.7892\n",
      "Epoch 4/100\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 36ms/step - accuracy: 0.6325 - loss: 0.7971 - val_accuracy: 0.6185 - val_loss: 0.8519\n",
      "Epoch 5/100\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 36ms/step - accuracy: 0.6328 - loss: 0.7910 - val_accuracy: 0.6570 - val_loss: 0.7690\n",
      "Epoch 6/100\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 28ms/step - accuracy: 0.6488 - loss: 0.7734 - val_accuracy: 0.6650 - val_loss: 0.7545\n",
      "Epoch 7/100\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 33ms/step - accuracy: 0.6548 - loss: 0.7569 - val_accuracy: 0.6447 - val_loss: 0.7704\n",
      "Epoch 8/100\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - accuracy: 0.6607 - loss: 0.7503 - val_accuracy: 0.6695 - val_loss: 0.7453\n",
      "Epoch 9/100\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - accuracy: 0.6629 - loss: 0.7538 - val_accuracy: 0.6753 - val_loss: 0.7353\n",
      "Epoch 10/100\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 32ms/step - accuracy: 0.6704 - loss: 0.7372 - val_accuracy: 0.6768 - val_loss: 0.7260\n",
      "Epoch 11/100\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 25ms/step - accuracy: 0.6826 - loss: 0.7223 - val_accuracy: 0.6773 - val_loss: 0.7422\n",
      "Epoch 12/100\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 36ms/step - accuracy: 0.6684 - loss: 0.7328 - val_accuracy: 0.6527 - val_loss: 0.7542\n",
      "Epoch 13/100\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 29ms/step - accuracy: 0.6790 - loss: 0.7230 - val_accuracy: 0.6668 - val_loss: 0.7346\n",
      "Epoch 14/100\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 36ms/step - accuracy: 0.6876 - loss: 0.7070 - val_accuracy: 0.6778 - val_loss: 0.7271\n",
      "Epoch 15/100\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 33ms/step - accuracy: 0.6863 - loss: 0.7070 - val_accuracy: 0.6821 - val_loss: 0.7354\n",
      "Epoch 16/100\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 35ms/step - accuracy: 0.6903 - loss: 0.6999 - val_accuracy: 0.6705 - val_loss: 0.7230\n",
      "Epoch 17/100\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 35ms/step - accuracy: 0.6867 - loss: 0.7009 - val_accuracy: 0.6725 - val_loss: 0.7459\n",
      "Epoch 18/100\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 35ms/step - accuracy: 0.7012 - loss: 0.6906 - val_accuracy: 0.6871 - val_loss: 0.7027\n",
      "Epoch 19/100\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 34ms/step - accuracy: 0.7112 - loss: 0.6712 - val_accuracy: 0.6768 - val_loss: 0.7356\n",
      "Epoch 20/100\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 31ms/step - accuracy: 0.7074 - loss: 0.6713 - val_accuracy: 0.6921 - val_loss: 0.7103\n",
      "Epoch 21/100\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 35ms/step - accuracy: 0.7047 - loss: 0.6800 - val_accuracy: 0.6888 - val_loss: 0.7259\n",
      "Epoch 22/100\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 38ms/step - accuracy: 0.7027 - loss: 0.6781 - val_accuracy: 0.6808 - val_loss: 0.7314\n",
      "Epoch 23/100\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 36ms/step - accuracy: 0.7225 - loss: 0.6531 - val_accuracy: 0.6944 - val_loss: 0.7172\n",
      "Epoch 24/100\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - accuracy: 0.7083 - loss: 0.6664 - val_accuracy: 0.6914 - val_loss: 0.7145\n",
      "Epoch 25/100\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - accuracy: 0.7132 - loss: 0.6590 - val_accuracy: 0.6919 - val_loss: 0.7218\n",
      "Epoch 26/100\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 43ms/step - accuracy: 0.7123 - loss: 0.6551 - val_accuracy: 0.6954 - val_loss: 0.7071\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "          InputLayer(input_shape=input_num_units),\n",
    "          Flatten(),\n",
    "          Dense(units=hidden_num_units, activation='relu'),\n",
    "          Dense(units=output_num_units, activation='softmax'),\n",
    "        ])\n",
    "\n",
    "# Defining parameters like optmizer, loss function and evaluating metric\n",
    "model.compile(loss='categorical_crossentropy', # \n",
    "        optimizer=keras.optimizers.Adam(), # Learning rate and momentum can be passed inside optimizer\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "# Defining early stopping callback.\n",
    "# After epoch 50, training can be stopped if not improved in 'val_loss' is seen\n",
    "\n",
    "cb_early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=8, min_delta=0.02) \n",
    "cb = keras.callbacks.TensorBoard(log_dir='early_stop', write_graph=False) \n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=epochs, validation_split=0.2, callbacks=[cb, cb_early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training stopped on epoch 21 due to `val_loss` not improving from min_delta = 0.02"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
